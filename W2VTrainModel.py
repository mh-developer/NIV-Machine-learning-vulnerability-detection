import os.path
import pickle

import nltk
from gensim.models import Word2Vec


class W2VTrainModel:
    def __init__(self):
        self.all_words = []
        self.mode = "withString"
        self.python_data = ""

        # Loading the training corpus
        with open(f'w2v/pythontraining_{self.mode}_X', 'r', encoding="utf8") as file:
            self.python_data = file.read().lower().replace('\n', ' ')

        print("Length of the training file: " + str(len(self.python_data)) + ".")
        print("It contains " + str(self.python_data.count(" ")) + " individual code tokens.")

    def preprocess_data(self):
        if os.path.isfile(f'data/pythontraining_processed_{self.mode}'):
            with open(f'data/pythontraining_processed_{self.mode}', 'rb', encoding="utf8") as fp:
                self.all_words = pickle.load(fp)
            print("loaded processed model.")
        else:
            print("now processing...")
            processed = self.python_data
            all_sentences = nltk.sent_tokenize(processed)
            self.all_words = [nltk.word_tokenize(sent) for sent in all_sentences]
            print("saving")
            with open(f'data/pythontraining_processed_{self.mode}', 'wb', encoding="utf8") as fp:
                pickle.dump(self.all_words, fp)

            print("processed.\n")

    def build_model(self):
        # build model with different parameters
        for min_count in [10, 30, 50, 100, 300, 500, 5000]:
            for iteration in [1, 5, 10, 30, 50, 100]:
                for size in [5, 10, 15, 30, 50, 75, 100, 200, 300]:

                    print("\n\n" + self.mode + " W2V model with min count " + str(min_count) + " and " + str(
                        iteration) + " Iterationen and size " + str(size))
                    fname = f"w2v/word2vec_{self.mode}{str(min_count)}-{str(iteration)}-{str(size)}.model"

                    if os.path.isfile(fname):
                        print("model already exists")
                        continue

                    else:
                        print("build model...")
                        model = Word2Vec(
                            self.all_words,
                            vector_size=size,
                            min_count=min_count,
                            window=iteration,
                            workers=4
                        )
                        vocabulary = model.wv.vocab

                        # words = ["import", "true", "while", "if", "try", "in", "+", "x", "=", ":", "[", "print", "str", "count", "len", "where", "join", "split", "==", "raw_input"]
                        # for similar in words:
                        #  try:
                        #    print("\n")
                        #    print(similar)
                        #    sim_words = model.wv.most_similar(similar)
                        #    print(sim_words)
                        #    print("\n")
                        #  except Exception as e:
                        #    print(e)
                        #    print("\n")

                        model.save(fname)


train_model = W2VTrainModel()
train_model.preprocess_data()
train_model.build_model()
